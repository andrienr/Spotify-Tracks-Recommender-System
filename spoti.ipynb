{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- 1. [Download data](#toc1_)    \n",
    "- 2. [Read and display data](#toc2_)    \n",
    "- 3. [Matrix Factorization model using alternating least squares](#toc3_)    \n",
    "  - 3.1. [Results](#toc3_1_)    \n",
    "- 4. [Multiclass classification model using neural networks](#toc4_)    \n",
    "  - 4.1. [extending item model considering tracks features](#toc4_1_)    \n",
    "    - 4.1.1. [retrieve data from spotify api](#toc4_1_1_)    \n",
    "    - 4.1.2. [prepare features](#toc4_1_2_)    \n",
    "    - 4.1.3. [build the item model](#toc4_1_3_)    \n",
    "  - 4.2. [extending user model considering playlist name](#toc4_2_)    \n",
    "    - 4.2.1. [prepare features](#toc4_2_1_)    \n",
    "    - 4.2.2. [build the user model](#toc4_2_2_)    \n",
    "  - 4.3. [Define metrics and loss](#toc4_3_)    \n",
    "  - 4.4. [Combine user and item models](#toc4_4_)    \n",
    "  - 4.5. [Results](#toc4_5_)    \n",
    "    - 4.5.1. [Comparison to MF model](#toc4_5_1_)    \n",
    "    - 4.5.2. [Using activation function](#toc4_5_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=true\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "– Describe the problem and the solution\n",
    "– Describe the results\n",
    "– Compare it with other approaches\n",
    "– Discuss benefits and limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. <a id='toc1_'></a>[Download data](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Spotify Million Playlist Dataset, available at https://www.aicrowd.com/challenges/spotify-million-playlist-dataset-challenge, contains 1,000,000 playlists, including playlist titles and track titles, created by users on the Spotify platform between January 2010 and October 2017."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 13:34:10.495191: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-06 13:34:10.690732: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-05-06 13:34:10.691584: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-06 13:34:11.791502: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/enrico/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.sparse import coo_matrix\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import bm25_weight\n",
    "from implicit import evaluation\n",
    "from tqdm import tqdm\n",
    "from zipfile import ZipFile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. <a id='toc2_'></a>[Read and display data](#toc0_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Playlists are extracted in the `data` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with ZipFile('spotify_million_playlist_dataset.zip', 'r') as zObject:\n",
    "#     zObject.extractall(\n",
    "#         path='mdp')\n",
    "\n",
    "slices_list = sorted(os.listdir('mdp/data'))\n",
    "len(slices_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "take the first 1*1000=1000 playlist, and compute the number of unique songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 34443\n"
     ]
    }
   ],
   "source": [
    "items = set()\n",
    "users = []\n",
    "for slice in slices_list[:1]:\n",
    "    with open(os.path.join(os.getcwd(),'mdp/data',slice),'r') as f:\n",
    "        js = json.load(f)\n",
    "        users.extend([[tl['track_uri'][14:] for tl in i['tracks']] for i in js['playlists']])\n",
    "        items.update(set([tr['track_uri'][14:]  for pl in js['playlists'] for tr in pl['tracks']]))\n",
    "print(len(users),len(items))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "util_matrices_dir = os.path.join(os.getcwd(),'util_matrices')\n",
    "if not os.path.isdir(util_matrices_dir):\n",
    "    os.makedirs(util_matrices_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = list(Path(util_matrices_dir).glob(f'*.csv'))\n",
    "for f in files:\n",
    "    os.remove(f)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [01:11<00:00, 13.93it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings = pd.DataFrame(columns=list(items))\n",
    "for i,lst in enumerate(tqdm(users)):\n",
    "    ratings.loc[len(ratings)]=0\n",
    "    ratings.iloc[len(ratings)-1,np.where(ratings.columns.isin(lst))] = 1\n",
    "    filename = str(len(users))+'x'+str(len(items))+'_part_'+str(i)+'.csv'\n",
    "    ratings.to_csv(Path(util_matrices_dir)/filename)\n",
    "    ratings.drop(ratings.index,inplace=True) \n",
    "len(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [12:19<00:00,  1.35it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 34444)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = list(Path(util_matrices_dir).glob(f'*.csv'))\n",
    "ratings = pd.concat([pd.read_csv(f) for f in tqdm(files)])\n",
    "ratings.shape "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we assume each playlist corresponds to a single user (this is not mentioned in the MPD description), so we can build the utility (user/item) matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix sparsity is 0.193709%\n"
     ]
    }
   ],
   "source": [
    "print(\"Matrix sparsity is \" + str(format(np.count_nonzero(ratings) / (ratings.shape[0]*ratings.shape[1]),'%')))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rank the 30 most popular songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nr. of likes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7KXjTSCq5nL1LoYtL7XAwS</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1xznGGDReH1oQq0xzbwXa3</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7yyRTcZmCiyzzJlNzGC9Ol</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7BKLCZ1jbUBVqRi2FVlTVw</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3a1lNhkSLSkpJE4MSHpDu9</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0QsvXIfqM0zZoerQfsI9lm</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6O6M7pJLABmfBRoGZMu76Y</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2EEeOnHehOozLq4aS0n6SL</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0VgkVdmE4gld66l8iyGjgx</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0SGkqnVQo9KPytSri1H6cF</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27GmP9AWRs744SzKcpJsTZ</th>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4Km5HrUvYTaSUfiSGPJeQR</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6eT7xZZlB2mwyzJ2sUKG6w</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7GX5flRQZVHRAGd6B4TmDO</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6gBFPUFcJLzWGx4lenP6h2</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5XJJdNPkwmbUwE79gv0NxK</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5hTpBe8h35rJ67eAWHQsJx</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62vpWI1CHwFy7tMIcSStl8</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12REd1n8PeiHHWOh066tpr</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0XUfyU2QviPAs6bxSpXYG4</th>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152lZdxL1OR0ZMW6KquMif</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69bp2EbF7Q2rqc5N3ylezZ</th>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4tCtwWceOPWzenK2HAIJSb</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5aAx2yezTd8zXrkmtKl66Z</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2d8JP84HNLKhmd6IYOoupQ</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5KY7zgFeH2GWoL1zP9mME6</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2KpCpk6HjXXLb7nnXoXA5O</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0v9Wz8o0BT8DU38R4ddjeH</th>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4X5f3vT8MRuXF68pfjNte5</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1AhDOtG9vPSOmsWgNW0BEY</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Nr. of likes\n",
       "7KXjTSCq5nL1LoYtL7XAwS            52\n",
       "1xznGGDReH1oQq0xzbwXa3            50\n",
       "7yyRTcZmCiyzzJlNzGC9Ol            49\n",
       "7BKLCZ1jbUBVqRi2FVlTVw            45\n",
       "3a1lNhkSLSkpJE4MSHpDu9            44\n",
       "0QsvXIfqM0zZoerQfsI9lm            41\n",
       "6O6M7pJLABmfBRoGZMu76Y            39\n",
       "2EEeOnHehOozLq4aS0n6SL            39\n",
       "0VgkVdmE4gld66l8iyGjgx            38\n",
       "0SGkqnVQo9KPytSri1H6cF            38\n",
       "27GmP9AWRs744SzKcpJsTZ            38\n",
       "4Km5HrUvYTaSUfiSGPJeQR            36\n",
       "6eT7xZZlB2mwyzJ2sUKG6w            36\n",
       "7GX5flRQZVHRAGd6B4TmDO            36\n",
       "6gBFPUFcJLzWGx4lenP6h2            35\n",
       "5XJJdNPkwmbUwE79gv0NxK            35\n",
       "5hTpBe8h35rJ67eAWHQsJx            35\n",
       "62vpWI1CHwFy7tMIcSStl8            34\n",
       "12REd1n8PeiHHWOh066tpr            34\n",
       "0XUfyU2QviPAs6bxSpXYG4            34\n",
       "152lZdxL1OR0ZMW6KquMif            33\n",
       "69bp2EbF7Q2rqc5N3ylezZ            33\n",
       "4tCtwWceOPWzenK2HAIJSb            32\n",
       "5aAx2yezTd8zXrkmtKl66Z            32\n",
       "2d8JP84HNLKhmd6IYOoupQ            32\n",
       "5KY7zgFeH2GWoL1zP9mME6            31\n",
       "2KpCpk6HjXXLb7nnXoXA5O            31\n",
       "0v9Wz8o0BT8DU38R4ddjeH            31\n",
       "4X5f3vT8MRuXF68pfjNte5            30\n",
       "1AhDOtG9vPSOmsWgNW0BEY            30"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pop_songs = ratings[ratings!=0].count(axis=0)\n",
    "\n",
    "pop_songs = pd.DataFrame( data= pop_songs.sort_values(ascending=False)[:30], columns =['Nr. of playlists'])\n",
    "display(pop_songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. <a id='toc3_'></a>[Matrix Factorization model using alternating least squares](#toc0_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "$$loss = \\sum_u \\sum_i { C_{ui}(P_{ui} - X_uY_i)^2} + \\lambda (\\|X_u\\|^2 + \\|Y_i\\|^2)  $$ \n",
    "$$ {C_{ui} = 1 + αr_{u}}$$\n",
    "\n",
    "rui\n",
    "indicates how many times u fully watched show i. For example, rui = 0.7 indicates that u watched 70% of the show,\n",
    "while for a user that watched the show twice we will set\n",
    "rui = 2\n",
    "\n",
    "references\n",
    "http://yifanhu.net/PUB/cf.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transorfm in scipy coordinate sparse matrix\n",
    "ratings_sparse = coo_matrix(ratings.values).tocsr()\n",
    "\n",
    "# weight for popular items\n",
    "ratings_sparse_weighted =  bm25_weight(ratings_sparse, K1=100, B=0.8)\n",
    "\n",
    "# split train/test\n",
    "train,test = evaluation.train_test_split(ratings_sparse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. <a id='toc3_1_'></a>[Results](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:15<00:00,  1.01s/it]\n",
      "100%|██████████| 983/983 [00:00<00:00, 2590.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "100%|██████████| 983/983 [00:00<00:00, 2027.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "100%|██████████| 983/983 [00:00<00:00, 2123.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:09<00:00,  1.60it/s]\n",
      "100%|██████████| 983/983 [00:00<00:00, 2423.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:09<00:00,  1.58it/s]\n",
      "100%|██████████| 983/983 [00:00<00:00, 2436.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:09<00:00,  1.51it/s]\n",
      "100%|██████████| 983/983 [00:00<00:00, 2018.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:11<00:00,  1.32it/s]\n",
      "100%|██████████| 983/983 [00:00<00:00, 1869.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:14<00:00,  1.03it/s]\n",
      "100%|██████████| 983/983 [00:00<00:00, 1832.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:10<00:00,  1.48it/s]\n",
      "100%|██████████| 983/983 [00:00<00:00, 1923.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha = 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 15/15 [00:10<00:00,  1.47it/s]\n",
      "100%|██████████| 983/983 [00:00<00:00, 1772.33it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0032784442291930557,\n",
       " 0.14395350570002236,\n",
       " 0.16727516578496388,\n",
       " 0.1724163624171075,\n",
       " 0.17569480664630058,\n",
       " 0.1794948215483198,\n",
       " 0.1788987407793756,\n",
       " 0.18061247299009014,\n",
       " 0.18143208404738842,\n",
       " 0.1817301244318605]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results=[]\n",
    "for i in range(10):\n",
    "    print('Alpha = '+str(i))\n",
    "    model = AlternatingLeastSquares(factors=64, regularization=0.05, alpha=i)\n",
    "    model.fit(train)\n",
    "    results.append(evaluation.precision_at_k(model,train,test,show_progress=True, K=100))\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. <a id='toc4_'></a>[Multiclass classification model using neural networks](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPLANATION\n",
    "\n",
    "$$loss = \\sum_u \\sum_i { C_{ui}(P_{ui} - X_uY_i)^2} + \\lambda (\\|X_u\\|^2 + \\|Y_i\\|^2)  $$ \n",
    "$$ {C_{ui} = 1 + αr_{u}}$$\n",
    "\n",
    "rui\n",
    "indicates how many times u fully watched show i. For example, rui = 0.7 indicates that u watched 70% of the show,\n",
    "while for a user that watched the show twice we will set\n",
    "rui = 2\n",
    "\n",
    "references\n",
    "http://yifanhu.net/PUB/cf.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. <a id='toc4_1_'></a>[extending item model considering tracks features](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. <a id='toc4_1_1_'></a>[retrieve data from spotify api](#toc0_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reference: https://developer.spotify.com/documentation/web-api/reference/get-several-audio-features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_download_dir = os.path.join(os.getcwd(), 'api_download/')\n",
    "if not os.path.isdir(api_download_dir):\n",
    "    os.makedirs(api_download_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BATCH_SIZE' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# BATCH_SIZE = 50\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# OAUTH_TOKEN = ''\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m chunks \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(tracks) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m BATCH_SIZE \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(chunks):\n\u001b[1;32m      6\u001b[0m      batch \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mlist\u001b[39m(tracks)[i\u001b[39m*\u001b[39mBATCH_SIZE:(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mBATCH_SIZE])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BATCH_SIZE' is not defined"
     ]
    }
   ],
   "source": [
    "# BATCH_SIZE = 50\n",
    "# OAUTH_TOKEN = ''\n",
    "\n",
    "chunks = (len(items) - 1) // BATCH_SIZE + 1\n",
    "for i in range(chunks):\n",
    "     batch = ','.join(list(items)[i*BATCH_SIZE:(i+1)*BATCH_SIZE])\n",
    "     filename = 'chunck_'+str(i)+'.json'  \n",
    "     !curl -X \"GET\" \"https://api.spotify.com/v1/audio-features?ids=\"+{batch} -H \"Accept: application/json\" -H \"Content-Type: application/json\" \\\n",
    "     -H \"Authorization: Bearer BQBvDlr6Qw3UzC6rQVtOAVXHd2eZkP84oqo8NODG-ogeY0H3WvfGXaWcq1ssBq6s7bjdQLwbTLQ3d0FAv9GoS-7vRDCgt956k-MO8vMR0-2p0Nx3VyOJxWPzQ4KFhAiBun7GuwY5L948wJ_2JDm74l9sfrm5ryX41vBqaicNrzQROQ\" | jq --raw-output  > {filename}      \n",
    "     ! mv chunck*.json api_download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. <a id='toc4_1_2_'></a>[prepare features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>key</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4Fpq4QkR06QRDkujBUk0JY</th>\n",
       "      <td>4</td>\n",
       "      <td>-7.371</td>\n",
       "      <td>138.389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5x5AACQgT2yK4VWwNn1bjO</th>\n",
       "      <td>0</td>\n",
       "      <td>-6.246</td>\n",
       "      <td>93.716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5IcMce4p9SbPwWeN4g4Oip</th>\n",
       "      <td>9</td>\n",
       "      <td>-12.957</td>\n",
       "      <td>99.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6cWlmDC8vU2WOMEID6ZL5K</th>\n",
       "      <td>4</td>\n",
       "      <td>-13.794</td>\n",
       "      <td>175.797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3DTy1olOsyxfLmgcym1PRC</th>\n",
       "      <td>8</td>\n",
       "      <td>-6.843</td>\n",
       "      <td>83.212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0NNKB1vQpy4eTeRFdalIDA</th>\n",
       "      <td>5</td>\n",
       "      <td>-12.224</td>\n",
       "      <td>99.965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0B7wvvmu9EISAwZnOpjhNI</th>\n",
       "      <td>0</td>\n",
       "      <td>-8.688</td>\n",
       "      <td>145.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2cViIXIe8Pbd1sOJExMJlK</th>\n",
       "      <td>1</td>\n",
       "      <td>-4.861</td>\n",
       "      <td>115.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1EZ0V24RlTzzwTM6FCNpWO</th>\n",
       "      <td>2</td>\n",
       "      <td>-9.138</td>\n",
       "      <td>152.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2dqRgUIrAX6Ptads6ttPDw</th>\n",
       "      <td>9</td>\n",
       "      <td>-6.922</td>\n",
       "      <td>84.414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33754 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       key loudness    tempo\n",
       "4Fpq4QkR06QRDkujBUk0JY   4   -7.371  138.389\n",
       "5x5AACQgT2yK4VWwNn1bjO   0   -6.246   93.716\n",
       "5IcMce4p9SbPwWeN4g4Oip   9  -12.957   99.494\n",
       "6cWlmDC8vU2WOMEID6ZL5K   4  -13.794  175.797\n",
       "3DTy1olOsyxfLmgcym1PRC   8   -6.843   83.212\n",
       "...                     ..      ...      ...\n",
       "0NNKB1vQpy4eTeRFdalIDA   5  -12.224   99.965\n",
       "0B7wvvmu9EISAwZnOpjhNI   0   -8.688  145.494\n",
       "2cViIXIe8Pbd1sOJExMJlK   1   -4.861  115.993\n",
       "1EZ0V24RlTzzwTM6FCNpWO   2   -9.138  152.921\n",
       "2dqRgUIrAX6Ptads6ttPDw   9   -6.922   84.414\n",
       "\n",
       "[33754 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "track_features_csv_name = 'track_features.csv'\n",
    "\n",
    "if os.path.exists(os.path.join(os.getcwd(), track_features_csv_name)):\n",
    "    track_features = pd.read_csv(track_features_csv_name, index_col=0)\n",
    "else:\n",
    "    track_features = pd.DataFrame(columns=['key','loudness','tempo'])\n",
    "    for chunck in os.listdir('api_download'):\n",
    "        with open(os.path.join(os.getcwd(),'api_download',chunck,),'r') as s:\n",
    "            for i in json.load(s)['audio_features']:\n",
    "                if i:\n",
    "                    track_features.loc[len(track_features)]= pd.Series(i, index=track_features.columns).T \n",
    "                    track_features.rename(index={len(track_features)-1:i['id']},inplace=True)\n",
    "    # 33754 < 34443 because of nulls\n",
    "    track_features.to_csv(track_features_csv_name)\n",
    "display(track_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99,\n",
       " 100,\n",
       " 101,\n",
       " 102,\n",
       " 103,\n",
       " 104,\n",
       " 105,\n",
       " 106,\n",
       " 107,\n",
       " 108,\n",
       " 109,\n",
       " 110,\n",
       " 111,\n",
       " 112,\n",
       " 113,\n",
       " 114,\n",
       " 115,\n",
       " 116,\n",
       " 117,\n",
       " 118,\n",
       " 119,\n",
       " 120,\n",
       " 121,\n",
       " 122,\n",
       " 123,\n",
       " 124,\n",
       " 125,\n",
       " 126,\n",
       " 127,\n",
       " 128,\n",
       " 129,\n",
       " 130,\n",
       " 131,\n",
       " 132,\n",
       " 133,\n",
       " 134,\n",
       " 135,\n",
       " 136,\n",
       " 137,\n",
       " 138,\n",
       " 139,\n",
       " 140,\n",
       " 141,\n",
       " 142,\n",
       " 143,\n",
       " 144,\n",
       " 145,\n",
       " 146,\n",
       " 147,\n",
       " 148,\n",
       " 149,\n",
       " 150,\n",
       " 151,\n",
       " 152,\n",
       " 153,\n",
       " 154,\n",
       " 155,\n",
       " 156,\n",
       " 157,\n",
       " 158,\n",
       " 159,\n",
       " 160,\n",
       " 161,\n",
       " 162,\n",
       " 163,\n",
       " 164,\n",
       " 165,\n",
       " 166,\n",
       " 167,\n",
       " 168,\n",
       " 169,\n",
       " 170,\n",
       " 171,\n",
       " 172,\n",
       " 173,\n",
       " 174,\n",
       " 175,\n",
       " 176,\n",
       " 177,\n",
       " 178,\n",
       " 179,\n",
       " 180,\n",
       " 181,\n",
       " 182,\n",
       " 183,\n",
       " 184,\n",
       " 185,\n",
       " 186,\n",
       " 187,\n",
       " 188,\n",
       " 189,\n",
       " 190,\n",
       " 191,\n",
       " 192,\n",
       " 193,\n",
       " 194,\n",
       " 195,\n",
       " 196,\n",
       " 197,\n",
       " 198,\n",
       " 199,\n",
       " 200,\n",
       " 201,\n",
       " 202,\n",
       " 203,\n",
       " 204,\n",
       " 205,\n",
       " 206,\n",
       " 207,\n",
       " 208,\n",
       " 209,\n",
       " 210,\n",
       " 211,\n",
       " 212,\n",
       " 213,\n",
       " 214,\n",
       " 215,\n",
       " 216,\n",
       " 217,\n",
       " 218,\n",
       " 219,\n",
       " 220,\n",
       " 221,\n",
       " 222,\n",
       " 223,\n",
       " 224,\n",
       " 225,\n",
       " 226,\n",
       " 227,\n",
       " 228,\n",
       " 229,\n",
       " 230,\n",
       " 231,\n",
       " 232,\n",
       " 233,\n",
       " 234,\n",
       " 235,\n",
       " 236,\n",
       " 237,\n",
       " 238,\n",
       " 239,\n",
       " 240,\n",
       " 241,\n",
       " 242,\n",
       " 243,\n",
       " 244,\n",
       " 245,\n",
       " 246,\n",
       " 247,\n",
       " 248,\n",
       " 249,\n",
       " 250,\n",
       " 251,\n",
       " 252,\n",
       " 253,\n",
       " 254,\n",
       " 255,\n",
       " 256,\n",
       " 257,\n",
       " 258,\n",
       " 259,\n",
       " 260,\n",
       " 261,\n",
       " 262,\n",
       " 263,\n",
       " 264,\n",
       " 265,\n",
       " 266,\n",
       " 267,\n",
       " 268,\n",
       " 269,\n",
       " 270,\n",
       " 271,\n",
       " 272,\n",
       " 273,\n",
       " 274,\n",
       " 275,\n",
       " 276,\n",
       " 277,\n",
       " 278,\n",
       " 279,\n",
       " 280,\n",
       " 281,\n",
       " 282,\n",
       " 283,\n",
       " 284,\n",
       " 285,\n",
       " 286,\n",
       " 287,\n",
       " 288,\n",
       " 289,\n",
       " 290,\n",
       " 291,\n",
       " 292,\n",
       " 293,\n",
       " 294,\n",
       " 295,\n",
       " 296,\n",
       " 297,\n",
       " 298,\n",
       " 299,\n",
       " 300,\n",
       " 301,\n",
       " 302,\n",
       " 303,\n",
       " 304,\n",
       " 305,\n",
       " 306,\n",
       " 307,\n",
       " 308,\n",
       " 309,\n",
       " 310,\n",
       " 311,\n",
       " 312,\n",
       " 313,\n",
       " 314,\n",
       " 315,\n",
       " 316,\n",
       " 317,\n",
       " 318,\n",
       " 319,\n",
       " 320,\n",
       " 321,\n",
       " 322,\n",
       " 323,\n",
       " 324,\n",
       " 325,\n",
       " 326,\n",
       " 327,\n",
       " 328,\n",
       " 329,\n",
       " 330,\n",
       " 331,\n",
       " 332,\n",
       " 333,\n",
       " 334,\n",
       " 335,\n",
       " 336,\n",
       " 337,\n",
       " 338,\n",
       " 339,\n",
       " 340,\n",
       " 341,\n",
       " 342,\n",
       " 343,\n",
       " 344,\n",
       " 345,\n",
       " 346,\n",
       " 347,\n",
       " 348,\n",
       " 349,\n",
       " 350,\n",
       " 351,\n",
       " 352,\n",
       " 353,\n",
       " 354,\n",
       " 355,\n",
       " 356,\n",
       " 357,\n",
       " 358,\n",
       " 359,\n",
       " 360,\n",
       " 361,\n",
       " 362,\n",
       " 363,\n",
       " 364,\n",
       " 365,\n",
       " 366,\n",
       " 367,\n",
       " 368,\n",
       " 369,\n",
       " 370,\n",
       " 371,\n",
       " 372,\n",
       " 373,\n",
       " 374,\n",
       " 375,\n",
       " 376,\n",
       " 377,\n",
       " 378,\n",
       " 379,\n",
       " 380,\n",
       " 381,\n",
       " 382,\n",
       " 383,\n",
       " 384,\n",
       " 385,\n",
       " 386,\n",
       " 387,\n",
       " 388,\n",
       " 389,\n",
       " 390,\n",
       " 391,\n",
       " 392,\n",
       " 393,\n",
       " 394,\n",
       " 395,\n",
       " 396,\n",
       " 397,\n",
       " 398,\n",
       " 399,\n",
       " 400,\n",
       " 401,\n",
       " 402,\n",
       " 403,\n",
       " 404,\n",
       " 405,\n",
       " 406,\n",
       " 407,\n",
       " 408,\n",
       " 409,\n",
       " 410,\n",
       " 411,\n",
       " 412,\n",
       " 413,\n",
       " 414,\n",
       " 415,\n",
       " 416,\n",
       " 417,\n",
       " 418,\n",
       " 419,\n",
       " 420,\n",
       " 421,\n",
       " 422,\n",
       " 423,\n",
       " 424,\n",
       " 425,\n",
       " 426,\n",
       " 427,\n",
       " 428,\n",
       " 429,\n",
       " 430,\n",
       " 431,\n",
       " 432,\n",
       " 433,\n",
       " 434,\n",
       " 435,\n",
       " 436,\n",
       " 437,\n",
       " 438,\n",
       " 439,\n",
       " 440,\n",
       " 441,\n",
       " 442,\n",
       " 443,\n",
       " 444,\n",
       " 445,\n",
       " 446,\n",
       " 447,\n",
       " 448,\n",
       " 449,\n",
       " 450,\n",
       " 451,\n",
       " 452,\n",
       " 453,\n",
       " 454,\n",
       " 455,\n",
       " 456,\n",
       " 457,\n",
       " 458,\n",
       " 459,\n",
       " 460,\n",
       " 461,\n",
       " 462,\n",
       " 463,\n",
       " 464,\n",
       " 465,\n",
       " 466,\n",
       " 467,\n",
       " 468,\n",
       " 469,\n",
       " 470,\n",
       " 471,\n",
       " 472,\n",
       " 473,\n",
       " 474,\n",
       " 475,\n",
       " 476,\n",
       " 477,\n",
       " 478,\n",
       " 479,\n",
       " 480,\n",
       " 481,\n",
       " 482,\n",
       " 483,\n",
       " 484,\n",
       " 485,\n",
       " 486,\n",
       " 487,\n",
       " 488,\n",
       " 489,\n",
       " 490,\n",
       " 491,\n",
       " 492,\n",
       " 493,\n",
       " 494,\n",
       " 495,\n",
       " 496,\n",
       " 497,\n",
       " 498,\n",
       " 499,\n",
       " 500,\n",
       " 501,\n",
       " 502,\n",
       " 503,\n",
       " 504,\n",
       " 505,\n",
       " 506,\n",
       " 507,\n",
       " 508,\n",
       " 509,\n",
       " 510,\n",
       " 511,\n",
       " 512,\n",
       " 513,\n",
       " 514,\n",
       " 515,\n",
       " 516,\n",
       " 517,\n",
       " 518,\n",
       " 519,\n",
       " 520,\n",
       " 521,\n",
       " 522,\n",
       " 523,\n",
       " 524,\n",
       " 525,\n",
       " 526,\n",
       " 527,\n",
       " 528,\n",
       " 529,\n",
       " 530,\n",
       " 531,\n",
       " 532,\n",
       " 533,\n",
       " 534,\n",
       " 535,\n",
       " 536,\n",
       " 537,\n",
       " 538,\n",
       " 539,\n",
       " 540,\n",
       " 541,\n",
       " 542,\n",
       " 543,\n",
       " 544,\n",
       " 545,\n",
       " 546,\n",
       " 547,\n",
       " 548,\n",
       " 549,\n",
       " 550,\n",
       " 551,\n",
       " 552,\n",
       " 553,\n",
       " 554,\n",
       " 555,\n",
       " 556,\n",
       " 557,\n",
       " 558,\n",
       " 559,\n",
       " 560,\n",
       " 561,\n",
       " 562,\n",
       " 563,\n",
       " 564,\n",
       " 565,\n",
       " 566,\n",
       " 567,\n",
       " 568,\n",
       " 569,\n",
       " 570,\n",
       " 571,\n",
       " 572,\n",
       " 573,\n",
       " 574,\n",
       " 575,\n",
       " 576,\n",
       " 577,\n",
       " 578,\n",
       " 579,\n",
       " 580,\n",
       " 581,\n",
       " 582,\n",
       " 583,\n",
       " 584,\n",
       " 585,\n",
       " 586,\n",
       " 587,\n",
       " 588,\n",
       " 589,\n",
       " 590,\n",
       " 591,\n",
       " 592,\n",
       " 593,\n",
       " 594,\n",
       " 595,\n",
       " 596,\n",
       " 597,\n",
       " 598,\n",
       " 599,\n",
       " 600,\n",
       " 601,\n",
       " 602,\n",
       " 603,\n",
       " 604,\n",
       " 605,\n",
       " 606,\n",
       " 607,\n",
       " 608,\n",
       " 609,\n",
       " 610,\n",
       " 611,\n",
       " 612,\n",
       " 613,\n",
       " 614,\n",
       " 615,\n",
       " 616,\n",
       " 617,\n",
       " 618,\n",
       " 619,\n",
       " 620,\n",
       " 621,\n",
       " 622,\n",
       " 623,\n",
       " 624,\n",
       " 625,\n",
       " 626,\n",
       " 627,\n",
       " 628,\n",
       " 629,\n",
       " 630,\n",
       " 631,\n",
       " 632,\n",
       " 633,\n",
       " 634,\n",
       " 635,\n",
       " 636,\n",
       " 637,\n",
       " 638,\n",
       " 639,\n",
       " 640,\n",
       " 641,\n",
       " 642,\n",
       " 643,\n",
       " 644,\n",
       " 645,\n",
       " 646,\n",
       " 647,\n",
       " 648,\n",
       " 649,\n",
       " 650,\n",
       " 651,\n",
       " 652,\n",
       " 653,\n",
       " 654,\n",
       " 655,\n",
       " 656,\n",
       " 657,\n",
       " 658,\n",
       " 659,\n",
       " 660,\n",
       " 661,\n",
       " 662,\n",
       " 663,\n",
       " 664,\n",
       " 665,\n",
       " 666,\n",
       " 667,\n",
       " 668,\n",
       " 669,\n",
       " 670,\n",
       " 671,\n",
       " 672,\n",
       " 673,\n",
       " 674,\n",
       " 675,\n",
       " 676,\n",
       " 677,\n",
       " 678,\n",
       " 679,\n",
       " 680,\n",
       " 681,\n",
       " 682,\n",
       " 683,\n",
       " 684,\n",
       " 685,\n",
       " 686,\n",
       " 687,\n",
       " 688,\n",
       " 689,\n",
       " 690,\n",
       " 691,\n",
       " 692,\n",
       " 693,\n",
       " 694,\n",
       " 695,\n",
       " 696,\n",
       " 697,\n",
       " 698,\n",
       " 699,\n",
       " 700,\n",
       " 701,\n",
       " 702,\n",
       " 703,\n",
       " 704,\n",
       " 705,\n",
       " 706,\n",
       " 707,\n",
       " 708,\n",
       " 709,\n",
       " 710,\n",
       " 711,\n",
       " 712,\n",
       " 713,\n",
       " 714,\n",
       " 715,\n",
       " 716,\n",
       " 717,\n",
       " 718,\n",
       " 719,\n",
       " 720,\n",
       " 721,\n",
       " 722,\n",
       " 723,\n",
       " 724,\n",
       " 725,\n",
       " 726,\n",
       " 727,\n",
       " 728,\n",
       " 729,\n",
       " 730,\n",
       " 731,\n",
       " 732,\n",
       " 733,\n",
       " 734,\n",
       " 735,\n",
       " 736,\n",
       " 737,\n",
       " 738,\n",
       " 739,\n",
       " 740,\n",
       " 741,\n",
       " 742,\n",
       " 743,\n",
       " 744,\n",
       " 745,\n",
       " 746,\n",
       " 747,\n",
       " 748,\n",
       " 749,\n",
       " 750,\n",
       " 751,\n",
       " 752,\n",
       " 753,\n",
       " 754,\n",
       " 755,\n",
       " 756,\n",
       " 757,\n",
       " 758,\n",
       " 759,\n",
       " 760,\n",
       " 761,\n",
       " 762,\n",
       " 763,\n",
       " 764,\n",
       " 765,\n",
       " 766,\n",
       " 767,\n",
       " 768,\n",
       " 769,\n",
       " 770,\n",
       " 771,\n",
       " 772,\n",
       " 773,\n",
       " 774,\n",
       " 775,\n",
       " 776,\n",
       " 777,\n",
       " 778,\n",
       " 779,\n",
       " 780,\n",
       " 781,\n",
       " 782,\n",
       " 783,\n",
       " 784,\n",
       " 785,\n",
       " 786,\n",
       " 787,\n",
       " 788,\n",
       " 789,\n",
       " 790,\n",
       " 791,\n",
       " 792,\n",
       " 793,\n",
       " 794,\n",
       " 795,\n",
       " 796,\n",
       " 797,\n",
       " 798,\n",
       " 799,\n",
       " 800,\n",
       " 801,\n",
       " 802,\n",
       " 803,\n",
       " 804,\n",
       " 805,\n",
       " 806,\n",
       " 807,\n",
       " 808,\n",
       " 809,\n",
       " 810,\n",
       " 811,\n",
       " 812,\n",
       " 813,\n",
       " 814,\n",
       " 815,\n",
       " 816,\n",
       " 817,\n",
       " 818,\n",
       " 819,\n",
       " 820,\n",
       " 821,\n",
       " 822,\n",
       " 823,\n",
       " 824,\n",
       " 825,\n",
       " 826,\n",
       " 827,\n",
       " 828,\n",
       " 829,\n",
       " 830,\n",
       " 831,\n",
       " 832,\n",
       " 833,\n",
       " 834,\n",
       " 835,\n",
       " 836,\n",
       " 837,\n",
       " 838,\n",
       " 839,\n",
       " 840,\n",
       " 841,\n",
       " 842,\n",
       " 843,\n",
       " 844,\n",
       " 845,\n",
       " 846,\n",
       " 847,\n",
       " 848,\n",
       " 849,\n",
       " 850,\n",
       " 851,\n",
       " 852,\n",
       " 853,\n",
       " 854,\n",
       " 855,\n",
       " 856,\n",
       " 857,\n",
       " 858,\n",
       " 859,\n",
       " 860,\n",
       " 861,\n",
       " 862,\n",
       " 863,\n",
       " 864,\n",
       " 865,\n",
       " 866,\n",
       " 867,\n",
       " 868,\n",
       " 869,\n",
       " 870,\n",
       " 871,\n",
       " 872,\n",
       " 873,\n",
       " 874,\n",
       " 875,\n",
       " 876,\n",
       " 877,\n",
       " 878,\n",
       " 879,\n",
       " 880,\n",
       " 881,\n",
       " 882,\n",
       " 883,\n",
       " 884,\n",
       " 885,\n",
       " 886,\n",
       " 887,\n",
       " 888,\n",
       " 889,\n",
       " 890,\n",
       " 891,\n",
       " 892,\n",
       " 893,\n",
       " 894,\n",
       " 895,\n",
       " 896,\n",
       " 897,\n",
       " 898,\n",
       " 899,\n",
       " 900,\n",
       " 901,\n",
       " 902,\n",
       " 903,\n",
       " 904,\n",
       " 905,\n",
       " 906,\n",
       " 907,\n",
       " 908,\n",
       " 909,\n",
       " 910,\n",
       " 911,\n",
       " 912,\n",
       " 913,\n",
       " 914,\n",
       " 915,\n",
       " 916,\n",
       " 917,\n",
       " 918,\n",
       " 919,\n",
       " 920,\n",
       " 921,\n",
       " 922,\n",
       " 923,\n",
       " 924,\n",
       " 925,\n",
       " 926,\n",
       " 927,\n",
       " 928,\n",
       " 929,\n",
       " 930,\n",
       " 931,\n",
       " 932,\n",
       " 933,\n",
       " 934,\n",
       " 935,\n",
       " 936,\n",
       " 937,\n",
       " 938,\n",
       " 939,\n",
       " 940,\n",
       " 941,\n",
       " 942,\n",
       " 943,\n",
       " 944,\n",
       " 945,\n",
       " 946,\n",
       " 947,\n",
       " 948,\n",
       " 949,\n",
       " 950,\n",
       " 951,\n",
       " 952,\n",
       " 953,\n",
       " 954,\n",
       " 955,\n",
       " 956,\n",
       " 957,\n",
       " 958,\n",
       " 959,\n",
       " 960,\n",
       " 961,\n",
       " 962,\n",
       " 963,\n",
       " 964,\n",
       " 965,\n",
       " 966,\n",
       " 967,\n",
       " 968,\n",
       " 969,\n",
       " 970,\n",
       " 971,\n",
       " 972,\n",
       " 973,\n",
       " 974,\n",
       " 975,\n",
       " 976,\n",
       " 977,\n",
       " 978,\n",
       " 979,\n",
       " 980,\n",
       " 981,\n",
       " 982,\n",
       " 983,\n",
       " 984,\n",
       " 985,\n",
       " 986,\n",
       " 987,\n",
       " 988,\n",
       " 989,\n",
       " 990,\n",
       " 991,\n",
       " 992,\n",
       " 993,\n",
       " 994,\n",
       " 995,\n",
       " 996,\n",
       " 997,\n",
       " 998,\n",
       " 999]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(len(users)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/enrico/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/numpy/core/numeric.py:2463: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  return bool(asarray(a1 == a2).all())\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type int).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mSequential([\n\u001b[0;32m----> 2\u001b[0m         tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mlayers\u001b[39m.\u001b[39;49mStringLookup(\n\u001b[1;32m      3\u001b[0m             vocabulary\u001b[39m=\u001b[39;49m\u001b[39mlist\u001b[39;49m(\u001b[39mrange\u001b[39;49m(\u001b[39mlen\u001b[39;49m(users))), mask_token\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m      4\u001b[0m         tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mEmbedding(\u001b[39mlen\u001b[39m(users) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m, \u001b[39m32\u001b[39m),\n\u001b[1;32m      5\u001b[0m     ])\n",
      "File \u001b[0;32m~/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/keras/layers/preprocessing/string_lookup.py:333\u001b[0m, in \u001b[0;36mStringLookup.__init__\u001b[0;34m(self, max_tokens, num_oov_indices, mask_token, oov_token, vocabulary, idf_weights, encoding, invert, output_mode, sparse, pad_to_max_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m     \u001b[39mdel\u001b[39;00m kwargs[\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m    331\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mencoding \u001b[39m=\u001b[39m encoding\n\u001b[0;32m--> 333\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m    334\u001b[0m     max_tokens\u001b[39m=\u001b[39;49mmax_tokens,\n\u001b[1;32m    335\u001b[0m     num_oov_indices\u001b[39m=\u001b[39;49mnum_oov_indices,\n\u001b[1;32m    336\u001b[0m     mask_token\u001b[39m=\u001b[39;49mmask_token,\n\u001b[1;32m    337\u001b[0m     oov_token\u001b[39m=\u001b[39;49moov_token,\n\u001b[1;32m    338\u001b[0m     vocabulary\u001b[39m=\u001b[39;49mvocabulary,\n\u001b[1;32m    339\u001b[0m     vocabulary_dtype\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mstring,\n\u001b[1;32m    340\u001b[0m     idf_weights\u001b[39m=\u001b[39;49midf_weights,\n\u001b[1;32m    341\u001b[0m     invert\u001b[39m=\u001b[39;49minvert,\n\u001b[1;32m    342\u001b[0m     output_mode\u001b[39m=\u001b[39;49moutput_mode,\n\u001b[1;32m    343\u001b[0m     sparse\u001b[39m=\u001b[39;49msparse,\n\u001b[1;32m    344\u001b[0m     pad_to_max_tokens\u001b[39m=\u001b[39;49mpad_to_max_tokens,\n\u001b[1;32m    345\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    346\u001b[0m )\n\u001b[1;32m    347\u001b[0m base_preprocessing_layer\u001b[39m.\u001b[39mkeras_kpl_gauge\u001b[39m.\u001b[39mget_cell(\u001b[39m\"\u001b[39m\u001b[39mStringLookup\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mset(\n\u001b[1;32m    348\u001b[0m     \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    349\u001b[0m )\n",
      "File \u001b[0;32m~/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py:322\u001b[0m, in \u001b[0;36mIndexLookup.__init__\u001b[0;34m(self, max_tokens, num_oov_indices, mask_token, oov_token, vocabulary_dtype, vocabulary, idf_weights, invert, output_mode, sparse, pad_to_max_tokens, **kwargs)\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39midf_weights_const \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39midf_weights\u001b[39m.\u001b[39mvalue()\n\u001b[1;32m    321\u001b[0m \u001b[39mif\u001b[39;00m vocabulary \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 322\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mset_vocabulary(vocabulary, idf_weights)\n\u001b[1;32m    323\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    324\u001b[0m     \u001b[39m# When restoring from a keras SavedModel, the loading code will\u001b[39;00m\n\u001b[1;32m    325\u001b[0m     \u001b[39m# expect to find and restore a lookup_table attribute on the layer.\u001b[39;00m\n\u001b[1;32m    326\u001b[0m     \u001b[39m# This table needs to be uninitialized as a StaticHashTable cannot\u001b[39;00m\n\u001b[1;32m    327\u001b[0m     \u001b[39m# be initialized twice.\u001b[39;00m\n\u001b[1;32m    328\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlookup_table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_uninitialized_lookup_table()\n",
      "File \u001b[0;32m~/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py:581\u001b[0m, in \u001b[0;36mIndexLookup.set_vocabulary\u001b[0;34m(self, vocabulary, idf_weights)\u001b[0m\n\u001b[1;32m    574\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_tokens \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m (new_vocab_size \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_tokens):\n\u001b[1;32m    575\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    576\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAttempted to set a vocabulary larger than the maximum vocab \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39msize. Passed vocab size is \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m, max vocab size is \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    578\u001b[0m             new_vocab_size, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_tokens\n\u001b[1;32m    579\u001b[0m         )\n\u001b[1;32m    580\u001b[0m     )\n\u001b[0;32m--> 581\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlookup_table \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_lookup_table_from_tokens(tokens)\n\u001b[1;32m    582\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_record_vocabulary_size()\n\u001b[1;32m    584\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_mode \u001b[39m==\u001b[39m TF_IDF \u001b[39mand\u001b[39;00m idf_weights \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/keras/layers/preprocessing/index_lookup.py:881\u001b[0m, in \u001b[0;36mIndexLookup._lookup_table_from_tokens\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    877\u001b[0m indices \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mrange(token_start, token_end, dtype\u001b[39m=\u001b[39mindices_dtype)\n\u001b[1;32m    878\u001b[0m keys, values \u001b[39m=\u001b[39m (\n\u001b[1;32m    879\u001b[0m     (indices, tokens) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minvert \u001b[39melse\u001b[39;00m (tokens, indices)\n\u001b[1;32m    880\u001b[0m )\n\u001b[0;32m--> 881\u001b[0m initializer \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mlookup\u001b[39m.\u001b[39;49mKeyValueTensorInitializer(\n\u001b[1;32m    882\u001b[0m     keys, values, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_key_dtype, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_value_dtype\n\u001b[1;32m    883\u001b[0m )\n\u001b[1;32m    884\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mlookup\u001b[39m.\u001b[39mStaticHashTable(initializer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_default_value)\n",
      "File \u001b[0;32m~/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/tensorflow/python/ops/lookup_ops.py:548\u001b[0m, in \u001b[0;36mKeyValueTensorInitializer.__init__\u001b[0;34m(self, keys, values, key_dtype, value_dtype, name)\u001b[0m\n\u001b[1;32m    545\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    546\u001b[0m         values, dtype\u001b[39m=\u001b[39mvalue_dtype, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    547\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 548\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_keys \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39;49mconvert_to_tensor(keys, dtype\u001b[39m=\u001b[39;49mkey_dtype, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mkeys\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    549\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mconvert_to_tensor(\n\u001b[1;32m    550\u001b[0m       values, dtype\u001b[39m=\u001b[39mvalue_dtype, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mvalues\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    551\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_name \u001b[39m=\u001b[39m name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mkey_value_init\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/tensorflow/python/profiler/trace.py:183\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/tensorflow/python/framework/ops.py:1642\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1633\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1634\u001b[0m           _add_error_prefix(\n\u001b[1;32m   1635\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConversion function \u001b[39m\u001b[39m{\u001b[39;00mconversion_func\u001b[39m!r}\u001b[39;00m\u001b[39m for type \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1638\u001b[0m               \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mactual = \u001b[39m\u001b[39m{\u001b[39;00mret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1639\u001b[0m               name\u001b[39m=\u001b[39mname))\n\u001b[1;32m   1641\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1642\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[1;32m   1644\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[1;32m   1645\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n",
      "File \u001b[0;32m~/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/tensorflow/python/framework/tensor_conversion_registry.py:48\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[1;32m     47\u001b[0m   \u001b[39mdel\u001b[39;00m as_ref  \u001b[39m# Unused.\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m   \u001b[39mreturn\u001b[39;00m constant_op\u001b[39m.\u001b[39;49mconstant(value, dtype, name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:268\u001b[0m, in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[1;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    173\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[1;32m    174\u001b[0m \n\u001b[1;32m    175\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[1;32m    267\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    269\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:280\u001b[0m, in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    279\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m--> 280\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m    282\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[1;32m    283\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n",
      "File \u001b[0;32m~/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:305\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[1;32m    304\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 305\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[1;32m    306\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n",
      "File \u001b[0;32m~/Univr/Mining massive datasets/project/venv/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:103\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m    102\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 103\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type int)."
     ]
    }
   ],
   "source": [
    "tf.keras.Sequential([\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=list(range(len(users))), mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(users) + 1, 32),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3. <a id='toc4_1_3_'></a>[build the item model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ItemModel(tf.keras.Model):\n",
    "  \n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "\n",
    "    self.user_embedding = \n",
    "\n",
    "    self.timestamp_embedding = tf.keras.Sequential([\n",
    "        tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "        tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
    "    ])\n",
    "    self.normalized_timestamp = tf.keras.layers.Normalization(\n",
    "        axis=None\n",
    "    )\n",
    "\n",
    "      self.normalized_timestamp.adapt(timestamps)\n",
    "\n",
    "  def call(self, inputs):\n",
    "\n",
    "    return tf.concat([\n",
    "        self.user_embedding(inputs[\"user_id\"]),\n",
    "        self.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "        tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. <a id='toc4_2_'></a>[extending user model considering playlist name](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. <a id='toc4_2_1_'></a>[prepare features](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_text = tf.keras.layers.TextVectorization()\n",
    "title_text.adapt(ratings.map(lambda x: x[\"movie_title\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. <a id='toc4_2_2_'></a>[build the user model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UserModel(tf.keras.Model):\n",
    "  \n",
    "  def __init__(self, use_timestamps):\n",
    "    super().__init__()\n",
    "\n",
    "    self._use_timestamps = use_timestamps\n",
    "\n",
    "    self.user_embedding = tf.keras.Sequential([\n",
    "        tf.keras.layers.StringLookup(\n",
    "            vocabulary=unique_user_ids, mask_token=None),\n",
    "        tf.keras.layers.Embedding(len(unique_user_ids) + 1, 32),\n",
    "    ])\n",
    "\n",
    "    if use_timestamps:\n",
    "      self.timestamp_embedding = tf.keras.Sequential([\n",
    "          tf.keras.layers.Discretization(timestamp_buckets.tolist()),\n",
    "          tf.keras.layers.Embedding(len(timestamp_buckets) + 1, 32),\n",
    "      ])\n",
    "      self.normalized_timestamp = tf.keras.layers.Normalization(\n",
    "          axis=None\n",
    "      )\n",
    "\n",
    "      self.normalized_timestamp.adapt(timestamps)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    if not self._use_timestamps:\n",
    "      return self.user_embedding(inputs[\"user_id\"])\n",
    "\n",
    "    return tf.concat([\n",
    "        self.user_embedding(inputs[\"user_id\"]),\n",
    "        self.timestamp_embedding(inputs[\"timestamp\"]),\n",
    "        tf.reshape(self.normalized_timestamp(inputs[\"timestamp\"]), (-1, 1)),\n",
    "    ], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. <a id='toc4_3_'></a>[Define metrics and loss](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "metrics = tfrs.metrics.FactorizedTopK(\n",
    "  candidates=movies.batch(128).map(movie_model)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "retrieval task is a keras layer with default loss function Categorical Cross Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = tfrs.tasks.Retrieval(\n",
    "  metrics=metrics,\n",
    "  batch_metrics=[tf.keras.metrics.Precision(top_k=2)]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. <a id='toc4_4_'></a>[Combine user and item models](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MovielensModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self, use_timestamps):\n",
    "    super().__init__()\n",
    "    self.query_model = tf.keras.Sequential([\n",
    "      UserModel(use_timestamps),\n",
    "      tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "    self.candidate_model = tf.keras.Sequential([\n",
    "      MovieModel(),\n",
    "      tf.keras.layers.Dense(32)\n",
    "    ])\n",
    "    self.task = tfrs.tasks.Retrieval(\n",
    "        metrics=tfrs.metrics.FactorizedTopK(\n",
    "            candidates=movies.batch(128).map(self.candidate_model),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "  def compute_loss(self, features, training=False):\n",
    "    # We only pass the user id and timestamp features into the query model. This\n",
    "    # is to ensure that the training inputs would have the same keys as the\n",
    "    # query inputs. Otherwise the discrepancy in input structure would cause an\n",
    "    # error when loading the query model after saving it.\n",
    "    query_embeddings = self.query_model({\n",
    "        \"user_id\": features[\"user_id\"],\n",
    "        \"timestamp\": features[\"timestamp\"],\n",
    "    })\n",
    "    movie_embeddings = self.candidate_model(features[\"movie_title\"])\n",
    "\n",
    "    return self.task(query_embeddings, movie_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5. <a id='toc4_5_'></a>[Results](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.1. <a id='toc4_5_1_'></a>[Comparison to MF model](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5.2. <a id='toc4_5_2_'></a>[Using activation function](#toc0_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9770c0d36b0d2663f8ec9f8baa969510f0f5d1b1ff853c7b4fdcb7cbd2f5034e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
